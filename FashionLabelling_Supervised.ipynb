{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionLabelling_Supervised.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNseqAQjgWUD9X2vzZ5rqTI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdnoon/Coursera_codes/blob/Introduction-to-TensorFlow/FashionLabelling_Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGdkt96K1P73"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rMOnmqH1wPv",
        "outputId": "4126bd42-8770-4566-825b-ceb15922bb59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Fashion MNIST data is available directly in the tf.keras datasets API. You load it like this:"
      ],
      "metadata": {
        "id": "NSFCu_yN16eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "QYpyxj_t11CM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture // hide output of Google colab cell\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "kM3AAGeF2DAx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling load_data on this object will give you two sets of two lists, these will be the training and testing values for the graphics "
      ],
      "metadata": {
        "id": "-rU14OVm2I8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[511])\n",
        "print(training_labels[511])\n",
        "print(training_images[511])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "JDMe3lXq2K95",
        "outputId": "a910c515-29c8-4a2d-b803-b8375bdb46fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[  0   0   0   0   0   0   0   0   0  21 154 135 146 143 101 135 129 126 152  39   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  96 255 253 254 255 232 247 254 254 253 116   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 123 233 216 223 226 230 224 234 217 216 113   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 156 233 227 233 233 225 224 236 225 220 149   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 157 225 228 232 230 222 224 232 227 215 163   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 177 229 224 222 226 222 227 231 228 222 186   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 180 234 216 219 234 233 230 231 215 222 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 153 237 210 221 226 181 252 224 216 232 165   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 124 248 213 223 216  35 255 221 208 239 130   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  81 240 200 225 233  14 255 218 198 240 101   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  55 217 193 238 224   0 254 206 181 236  81   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  37 209 159 216 218   0 239 182 151 227  63   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  16 222 141 214 217   0 232 198 153 237  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   5 224 136 209 195   0 219 196 145 241  45   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   2 226 152 206 185   0 211 197 137 235  28   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 214 155 215 177   0 200 207 133 230   9   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 211 158 210 155   0 191 217 150 219   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 208 165 213 142   0 189 204 161 219   2   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 206 178 215 151   0 169 204 164 211   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 212 207 223 153   0 154 209 173 212   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 201 221 226 150   0 154 218 190 214   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 193 224 230 151   0 151 226 203 212   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 194 226 228 159   0 147 236 215 210   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 190 228 231 171   0 143 244 222 205   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 184 228 231 173   0 136 248 226 202   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 177 227 230 167   0 127 244 228 194   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 219 242 244 193   0 158 253 244 224   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  94 140 125  71   0  74 158 156 108   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'...and fortunately in Python it's easy to normalize a list like this without looping."
      ],
      "metadata": {
        "id": "TBSZQpTY2u2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "KKgzS7QS2wC6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "metadata": {
        "id": "F1l3RlZe3n10"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential**: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "**Flatten**: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
        "\n",
        "**Dense**: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
        "\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ],
      "metadata": {
        "id": "dzUvHE2G4bij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzGDbCxh4YnS",
        "outputId": "0a4fa49a-920f-4b2c-cc54-77cf999f6b9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4986 - accuracy: 0.8249\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3789 - accuracy: 0.8629\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3377 - accuracy: 0.8764\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3139 - accuracy: 0.8854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2954 - accuracy: 0.8911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe572ce690>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss는 손실함수를 의미합니다. 모델을 훈련시킬때 이 손실 함수를 최소로 만들어주는 가중치들을 찾는 것\n",
        "반면 metric은 평가지표입니다. 검증셋에서 훈련된 모델의 성능을 평가할 때 어떤 평가지표로 평가할지를 결정해줍니다. 학습곡선을 그릴 때 손실함수와 평가지표를 에포크(epoch)마다 계산한 것을 그려주는데, 손실함수의 추이와 평가지표의 추이를 비교해보면서 모델이 과대적합(overfit) 또는 과소적합(underfit)되고 있는지 여부를 확인할 수 있습니다. 위 예에서는 평가지표로 MAE를 사용했습니다. 중요한 것은 평가지표로 어떤 것을 사용하더라도 모델 가중치의 업데이트에는 영향을 미치지 않는다는 사실입니다. \n",
        "\n",
        "**loss: 손실함수. 훈련셋과 연관. 훈련에 사용.**\n",
        "\n",
        "**metric: 평가지표. 검증셋과 연관. 훈련 과정을 모니터링하는데 사용.**"
      ],
      "metadata": {
        "id": "cbMCFhwd_nyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "about 91% accurate - Not great, but not bad considering it was only trained for 5 epochs and done quite quickly. But how would it work with unseen data? "
      ],
      "metadata": {
        "id": "Sp8uCAX26kK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5bs-3Sf6nNj",
        "outputId": "8ba6456f-950e-4f51-897b-1aee46fd8121"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3614906370639801, 0.8693000078201294]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise** :\n",
        "\n",
        "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
      ],
      "metadata": {
        "id": "B32VkIJ69uDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.6): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jwOWhKz96gl",
        "outputId": "07bf4173-36f0-4d25-da99-5fe5254ccc54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.8300\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4728 - accuracy: 0.8303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe5723f350>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}