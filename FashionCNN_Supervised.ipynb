{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionCNN_Supervised.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNprOhahsPjr0w6IQoHlAJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdnoon/Coursera_codes/blob/Introduction-to-TensorFlow/FashionCNN_Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN** - ultimate concept is that they narrow down the content of the image to focus on specific parts and this will likely improve the model accuracy. This is perfect for computer vision because it often highlights features that distinguish one item from another. Moreover, the amount of information needed is then much less because you'll just train on the highlighted features. That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focused and possibly more accurate."
      ],
      "metadata": {
        "id": "BIGJsCq0zDAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a CNN to label fasion MNIST"
      ],
      "metadata": {
        "id": "F2si3fEJzlmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv = 필터 입히기 - filter size (i.e. 3x3), filter # (i.e. 32 filters - each for different feature recognition)\n",
        "\n",
        "cf. stride - 필터 적용하는 간격. padding - 가장자리 픽셀을 0픽셀로 둘러싸는 두께.\n",
        "MaxPooling = 특정 사이즈(i.e. 2x2) 크기로 전체 픽셀을 조각내어 조각마다 max 값만 남기는 식으로 화면을 압축."
      ],
      "metadata": {
        "id": "aAHgxsEf0tuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "SQKfQ_gjzjku"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                                         \n",
        "  # Add convolutions and max pooling\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)), # initial 28 x 28 x 1 grayscale, 32 filters of 3x3 size\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'), # input_shape command not necessary for conv2D layer\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "-DNJYA3fzMce"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Use same settings\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HsG-ggL0Vao",
        "outputId": "8131eda5-6694-47ca-f17d-1b0a02327315"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 800)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               102528    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.4748 - accuracy: 0.8285\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.3211 - accuracy: 0.8832\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.2756 - accuracy: 0.8984\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.2483 - accuracy: 0.9064\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2220 - accuracy: 0.9176\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.2660 - accuracy: 0.8978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the code again, and see, step by step how the convolutions were built. Instead of the input layer at the top, you added a Conv2D layer. The parameters are:\n",
        "\n",
        "The number of convolutions you want to generate. The value here is purely arbitrary but it's good to use powers of 2 starting from 32.\n",
        "The size of the Convolution. In this case, a 3x3 grid.\n",
        "The activation function to use. In this case, you used a ReLU, which you might recall is the equivalent of returning x when x>0, else return 0.\n",
        "In the first layer, the shape of the input data."
      ],
      "metadata": {
        "id": "FCYELzuN16aR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About overfitting\n",
        "Try running the training for more epochs -- say about 20, and explore the results. In a nutshell, overfitting occurs when the network learns the data from the training set really well, but it's too specialised to only that data, and as a result is less effective at interpreting other unseen data. For example, if all your life you only saw red shoes, then when you see a red shoe you would be very good at identifying it. But blue suede shoes might confuse you."
      ],
      "metadata": {
        "id": "v0oYeuwI2H6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISES\n",
        "\n",
        "1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.\n",
        "\n",
        "          64 : accuracy 증가. training time 2배 증가. (train 93% test 91%)\n",
        "\n",
        "2. Remove the final Convolution. What impact will this have on accuracy or training time?\n",
        "\n",
        "          accuracy 증가. training time은 감소. but overfitting 위험 (train 94% test 91.5%)\n",
        "\n",
        "3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.\n",
        "\n",
        "          accuracy 감소 (train 89% test 88%). Underfitting 가능성.\n",
        "\n",
        "4. Remove all Convolutions but the first. What impact do you think this will have? Experiment with it.  -- Exercise 2 와 구분 안됨.\n",
        "\n",
        "5. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here.\n",
        "\n",
        "          Conv64로 했는데 epoch 3(90%)에서 중단하니 시간절약 (train 90% test 89%)"
      ],
      "metadata": {
        "id": "U4nHDi892qoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "nobzUq9y3JJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                                         \n",
        "  # Add convolutions and max pooling\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), # initial 28 x 28 x 1 grayscale, 32 filters of 3x3 size\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # input_shape command not necessary for conv2D layer\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# Use same settings\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xzcEmsga3NX-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ap-W-sy3SgR",
        "outputId": "7d34cd5f-01dc-499e-9c1b-95c4d8cdb8e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.4498 - accuracy: 0.8372\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.2985 - accuracy: 0.8903\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.2524 - accuracy: 0.9065\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.2169 - accuracy: 0.9196\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.1904 - accuracy: 0.9290\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2573 - accuracy: 0.9071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ],
      "metadata": {
        "id": "WYnghbD-6Hl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                                         \n",
        "  # Add convolutions and max pooling\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)), # initial 28 x 28 x 1 grayscale, 32 filters of 3x3 size\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# Use same settings\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nrXbSQOX6GAq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MSgKbUB6GKU",
        "outputId": "b8aa44fe-bb86-4be1-fadc-537cffb48f39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3919 - accuracy: 0.8605\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2652 - accuracy: 0.9039\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2196 - accuracy: 0.9205\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1895 - accuracy: 0.9306\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1606 - accuracy: 0.9402\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2477 - accuracy: 0.9155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3"
      ],
      "metadata": {
        "id": "H26VSqYO8BFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                                         \n",
        "  # Add convolutions and max pooling\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)), # initial 28 x 28 x 1 grayscale, 32 filters of 3x3 size\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# Use same settings\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CE3Sqeje8CrF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O98c9Zh28Uf2",
        "outputId": "6079d784-3ba6-407e-fb17-07d817a1c8ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.6389 - accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.4341 - accuracy: 0.8418\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.3799 - accuracy: 0.8597\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 51s 27ms/step - loss: 0.3437 - accuracy: 0.8733\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.3186 - accuracy: 0.8831\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3591 - accuracy: 0.8720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5"
      ],
      "metadata": {
        "id": "T1_jo2tj-BDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                                         \n",
        "  # Add convolutions and max pooling\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), # initial 28 x 28 x 1 grayscale, 32 filters of 3x3 size\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # input_shape command not necessary for conv2D layer\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# Use same settings\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "giRHTYIG-C40"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.9): # Experiment with changing this value\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hda1rd-HWl",
        "outputId": "762f747a-4b05-4aab-aa8f-13e2b48638a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.4464 - accuracy: 0.8368\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.2992 - accuracy: 0.8898\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9074\n",
            "Reached 90% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.2517 - accuracy: 0.9074\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.2874 - accuracy: 0.8923\n"
          ]
        }
      ]
    }
  ]
}